{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment By\n",
    "\n",
    "* **Muhammad Raaid Khan**\n",
    "* **PGD Batch-05**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Admission Predictions (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Suppress TensorFlow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv('/tf/Admission_Predict_Ver1.1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['Serial No.'],inplace=True)  # Remove un-necessary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA',\n",
       "       'Research', 'Chance of Admit '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Chance of Admit '])\n",
    "y = df['Chance of Admit '].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>324</td>\n",
       "      <td>105</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>340</td>\n",
       "      <td>115</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>320</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>301</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>323</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>305</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>321</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>305</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>311</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>302</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "153        324          105                  3  3.0   4.0  8.75         0\n",
       "84         340          115                  5  4.5   4.5  9.45         1\n",
       "310        320          104                  3  3.0   3.5  8.74         1\n",
       "494        301           99                  3  2.5   2.0  8.45         1\n",
       "126        323          113                  3  4.0   3.0  9.32         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "343        305          103                  2  2.5   3.5  8.13         0\n",
       "359        321          107                  2  2.0   1.5  8.44         0\n",
       "323        305          102                  2  2.0   2.5  8.18         0\n",
       "280        311          102                  3  4.5   4.0  8.64         1\n",
       "8          302          102                  1  2.0   1.5  8.00         0\n",
       "\n",
       "[350 rows x 7 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>328</td>\n",
       "      <td>115</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>310</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>311</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>295</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>312</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>334</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>295</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>329</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>328</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "69         328          115                  4  4.5   4.0  9.16         1\n",
       "29         310           99                  2  1.5   2.0  7.30         0\n",
       "471        311          103                  3  2.0   4.0  8.09         0\n",
       "344        295           96                  2  1.5   2.0  7.34         0\n",
       "54         322          110                  3  3.0   3.5  8.00         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "308        312          108                  3  3.5   3.0  8.53         0\n",
       "171        334          117                  5  4.0   4.5  9.07         1\n",
       "457        295           99                  1  2.0   1.5  7.57         0\n",
       "75         329          114                  2  2.0   4.0  8.56         1\n",
       "311        328          108                  4  4.5   4.0  9.18         1\n",
       "\n",
       "[150 rows x 7 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79, 0.94, 0.76, 0.68, 0.85, 0.92, 0.85, 0.59, 0.63, 0.52, 0.9 ,\n",
       "       0.77, 0.73, 0.51, 0.78, 0.75, 0.55, 0.83, 0.62, 0.5 , 0.72, 0.96,\n",
       "       0.67, 0.88, 0.67, 0.87, 0.83, 0.44, 0.61, 0.61, 0.57, 0.94, 0.9 ,\n",
       "       0.52, 0.84, 0.7 , 0.89, 0.82, 0.81, 0.61, 0.8 , 0.42, 0.54, 0.43,\n",
       "       0.73, 0.45, 0.54, 0.54, 0.78, 0.48, 0.89, 0.9 , 0.79, 0.52, 0.93,\n",
       "       0.94, 0.89, 0.89, 0.71, 0.8 , 0.84, 0.42, 0.94, 0.64, 0.51, 0.74,\n",
       "       0.53, 0.87, 0.77, 0.67, 0.64, 0.61, 0.9 , 0.85, 0.74, 0.71, 0.89,\n",
       "       0.76, 0.79, 0.88, 0.66, 0.48, 0.71, 0.75, 0.73, 0.66, 0.64, 0.52,\n",
       "       0.8 , 0.63, 0.79, 0.95, 0.77, 0.55, 0.78, 0.78, 0.79, 0.69, 0.83,\n",
       "       0.64, 0.49, 0.65, 0.85, 0.93, 0.74, 0.84, 0.79, 0.91, 0.72, 0.85,\n",
       "       0.71, 0.76, 0.91, 0.82, 0.61, 0.67, 0.96, 0.76, 0.45, 0.66, 0.49,\n",
       "       0.76, 0.72, 0.81, 0.78, 0.78, 0.61, 0.67, 0.82, 0.65, 0.59, 0.68,\n",
       "       0.77, 0.72, 0.64, 0.62, 0.72, 0.8 , 0.53, 0.92, 0.82, 0.74, 0.82,\n",
       "       0.71, 0.59, 0.8 , 0.58, 0.7 , 0.73, 0.66, 0.66, 0.67, 0.64, 0.84,\n",
       "       0.89, 0.78, 0.77, 0.8 , 0.96, 0.71, 0.92, 0.7 , 0.63, 0.87, 0.74,\n",
       "       0.67, 0.62, 0.84, 0.64, 0.81, 0.58, 0.96, 0.91, 0.79, 0.69, 0.79,\n",
       "       0.94, 0.97, 0.64, 0.96, 0.53, 0.7 , 0.54, 0.64, 0.81, 0.94, 0.8 ,\n",
       "       0.72, 0.68, 0.69, 0.84, 0.96, 0.46, 0.54, 0.91, 0.34, 0.75, 0.73,\n",
       "       0.75, 0.8 , 0.89, 0.71, 0.76, 0.57, 0.68, 0.58, 0.78, 0.66, 0.56,\n",
       "       0.74, 0.66, 0.69, 0.76, 0.79, 0.92, 0.8 , 0.76, 0.91, 0.68, 0.84,\n",
       "       0.56, 0.57, 0.7 , 0.78, 0.7 , 0.7 , 0.45, 0.93, 0.79, 0.73, 0.7 ,\n",
       "       0.82, 0.93, 0.74, 0.76, 0.62, 0.66, 0.79, 0.74, 0.71, 0.86, 0.59,\n",
       "       0.42, 0.75, 0.68, 0.68, 0.36, 0.94, 0.52, 0.69, 0.71, 0.64, 0.71,\n",
       "       0.71, 0.9 , 0.93, 0.56, 0.93, 0.53, 0.66, 0.95, 0.49, 0.94, 0.77,\n",
       "       0.91, 0.89, 0.71, 0.92, 0.73, 0.92, 0.42, 0.68, 0.76, 0.65, 0.65,\n",
       "       0.87, 0.62, 0.93, 0.52, 0.97, 0.6 , 0.86, 0.58, 0.86, 0.61, 0.86,\n",
       "       0.64, 0.73, 0.62, 0.72, 0.67, 0.7 , 0.78, 0.8 , 0.71, 0.56, 0.91,\n",
       "       0.69, 0.47, 0.72, 0.72, 0.7 , 0.75, 0.72, 0.58, 0.94, 0.73, 0.78,\n",
       "       0.82, 0.93, 0.87, 0.38, 0.65, 0.71, 0.82, 0.81, 0.9 , 0.96, 0.76,\n",
       "       0.49, 0.77, 0.77, 0.46, 0.72, 0.44, 0.71, 0.63, 0.36, 0.54, 0.69,\n",
       "       0.71, 0.97, 0.73, 0.6 , 0.58, 0.61, 0.63, 0.61, 0.72, 0.59, 0.58,\n",
       "       0.74, 0.89, 0.86, 0.46, 0.59, 0.81, 0.62, 0.68, 0.5 ])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78, 0.54, 0.64, 0.47, 0.7 , 0.88, 0.57, 0.72, 0.84, 0.64, 0.79,\n",
       "       0.56, 0.92, 0.79, 0.73, 0.52, 0.62, 0.81, 0.57, 0.65, 0.93, 0.65,\n",
       "       0.86, 0.87, 0.97, 0.65, 0.57, 0.95, 0.91, 0.74, 0.85, 0.81, 0.73,\n",
       "       0.39, 0.8 , 0.79, 0.73, 0.65, 0.58, 0.75, 0.94, 0.71, 0.86, 0.78,\n",
       "       0.87, 0.56, 0.62, 0.95, 0.93, 0.62, 0.81, 0.74, 0.84, 0.96, 0.46,\n",
       "       0.88, 0.64, 0.9 , 0.78, 0.71, 0.64, 0.73, 0.47, 0.93, 0.75, 0.68,\n",
       "       0.78, 0.34, 0.83, 0.9 , 0.94, 0.73, 0.71, 0.87, 0.64, 0.79, 0.59,\n",
       "       0.7 , 0.95, 0.92, 0.64, 0.65, 0.91, 0.73, 0.91, 0.76, 0.54, 0.68,\n",
       "       0.76, 0.68, 0.72, 0.67, 0.67, 0.94, 0.93, 0.77, 0.86, 0.8 , 0.64,\n",
       "       0.84, 0.57, 0.62, 0.94, 0.53, 0.64, 0.69, 0.65, 0.63, 0.57, 0.47,\n",
       "       0.57, 0.89, 0.8 , 0.86, 0.65, 0.63, 0.71, 0.61, 0.56, 0.72, 0.86,\n",
       "       0.76, 0.44, 0.62, 0.71, 0.74, 0.71, 0.38, 0.62, 0.82, 0.46, 0.79,\n",
       "       0.68, 0.67, 0.48, 0.9 , 0.73, 0.92, 0.77, 0.73, 0.7 , 0.47, 0.49,\n",
       "       0.57, 0.71, 0.69, 0.89, 0.37, 0.72, 0.84])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Scaler to Use\n",
    "\n",
    "* It you know upper and lower limit of feature, Use **Min Max Scaler** (i.e for GRE and TOEFL we know upper and lower limit)\n",
    "* Otherwise, use **Standard Scaler**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)  # fit_transform for training > Since the Model is seeing Data for First Time\n",
    "X_test = scaler.transform(X_test)        # transform for testing      > The Model has already seen the Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(7, activation='relu', input_dim=7), \n",
    "    tf.keras.layers.Dense(7, activation='relu'),\n",
    "    tf.keras.layers.Dense(7, activation='relu'),\n",
    "    tf.keras.layers.Dense(7, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_53 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 232 (928.00 Byte)\n",
      "Trainable params: 232 (928.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "9/9 [==============================] - 1s 19ms/step - loss: 0.5327 - val_loss: 0.4302\n",
      "Epoch 2/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4337 - val_loss: 0.3340\n",
      "Epoch 3/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3324 - val_loss: 0.2437\n",
      "Epoch 4/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2380 - val_loss: 0.1641\n",
      "Epoch 5/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1540 - val_loss: 0.0967\n",
      "Epoch 6/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0839 - val_loss: 0.0468\n",
      "Epoch 7/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0379 - val_loss: 0.0233\n",
      "Epoch 8/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0221\n",
      "Epoch 9/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0176 - val_loss: 0.0238\n",
      "Epoch 10/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0208\n",
      "Epoch 11/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0153 - val_loss: 0.0187\n",
      "Epoch 12/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0175\n",
      "Epoch 13/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0167\n",
      "Epoch 14/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0159\n",
      "Epoch 15/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0153\n",
      "Epoch 16/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0146\n",
      "Epoch 17/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0139\n",
      "Epoch 18/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0132\n",
      "Epoch 19/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 20/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0124\n",
      "Epoch 21/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0120\n",
      "Epoch 22/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0116\n",
      "Epoch 23/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0114\n",
      "Epoch 24/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0111\n",
      "Epoch 25/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0108\n",
      "Epoch 26/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0106\n",
      "Epoch 27/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 28/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0102\n",
      "Epoch 29/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 30/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0099\n",
      "Epoch 31/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0097\n",
      "Epoch 32/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0096\n",
      "Epoch 33/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0094\n",
      "Epoch 34/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0093\n",
      "Epoch 35/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0092\n",
      "Epoch 36/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0078 - val_loss: 0.0091\n",
      "Epoch 37/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0090\n",
      "Epoch 38/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0089\n",
      "Epoch 39/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0088\n",
      "Epoch 40/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0087\n",
      "Epoch 41/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0087\n",
      "Epoch 42/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0086\n",
      "Epoch 43/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0085\n",
      "Epoch 44/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0085\n",
      "Epoch 45/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0084\n",
      "Epoch 46/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0083\n",
      "Epoch 47/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 48/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 49/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 50/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 51/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 52/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 53/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0079\n",
      "Epoch 54/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 55/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 56/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 57/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 58/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 59/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 60/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 61/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 62/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 63/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0074\n",
      "Epoch 64/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 65/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 66/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 67/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 68/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 69/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 70/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 71/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 72/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0062 - val_loss: 0.0070\n",
      "Epoch 73/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0070\n",
      "Epoch 74/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0069\n",
      "Epoch 75/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0061 - val_loss: 0.0069\n",
      "Epoch 76/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 77/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 78/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0068\n",
      "Epoch 79/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0068\n",
      "Epoch 80/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0060 - val_loss: 0.0067\n",
      "Epoch 81/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 82/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 83/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 84/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 85/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 86/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 87/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0065\n",
      "Epoch 88/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0065\n",
      "Epoch 89/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0065\n",
      "Epoch 90/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0065\n",
      "Epoch 91/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 92/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0057 - val_loss: 0.0064\n",
      "Epoch 93/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0064\n",
      "Epoch 94/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0063\n",
      "Epoch 95/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0063\n",
      "Epoch 96/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0063\n",
      "Epoch 97/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0063\n",
      "Epoch 98/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0063\n",
      "Epoch 99/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 100/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 101/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 102/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 103/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 104/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 105/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 106/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 107/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 108/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 109/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 110/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 111/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 112/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 113/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 114/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 115/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0059\n",
      "Epoch 116/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 117/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 118/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 119/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 120/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 121/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 122/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 123/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 124/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 125/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 126/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 127/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 128/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 129/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 130/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0056\n",
      "Epoch 131/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0056\n",
      "Epoch 132/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 133/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 134/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 135/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 136/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 137/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 138/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 139/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0050 - val_loss: 0.0055\n",
      "Epoch 140/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 141/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 142/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 143/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 144/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 145/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 146/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 147/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 148/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 149/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 150/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 151/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 152/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 153/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 154/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 155/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 156/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0053\n",
      "Epoch 157/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 158/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 159/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 160/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 161/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 162/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 163/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 164/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 165/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 166/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 167/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 168/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 169/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 170/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 171/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 172/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 173/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 174/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 175/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 176/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 177/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 178/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 179/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 180/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 181/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 182/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 183/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 184/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 185/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 186/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 187/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 188/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 189/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 190/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 191/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 192/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 193/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 194/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 195/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 196/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 197/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 198/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 199/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 200/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 201/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 202/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 203/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 204/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 205/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 206/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 207/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 208/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 209/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 210/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 211/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 212/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 213/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 214/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 215/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 216/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 217/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 218/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 219/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 220/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 221/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 222/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 223/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 224/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 225/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 226/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 227/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 228/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 229/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 230/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 231/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 232/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 233/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 234/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 235/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 236/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 237/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 238/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 239/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 240/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 241/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 242/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 243/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 244/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 245/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 246/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 247/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 248/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 249/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 250/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 251/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 252/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 253/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 254/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 255/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 256/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 257/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 258/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 259/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 260/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 261/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 262/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 263/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 264/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 265/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 266/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 267/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 268/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 269/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 270/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 271/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 272/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 273/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 274/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 275/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 276/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 277/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 278/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 279/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 280/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 281/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 282/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 283/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 284/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 285/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 286/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 287/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 288/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 289/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 290/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 291/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 292/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 293/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 294/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 295/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 296/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 297/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 298/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 299/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 300/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 301/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 302/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 303/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 304/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 305/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 306/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 307/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 308/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 309/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 310/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 311/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 312/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 313/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 314/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 315/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 316/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 317/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 318/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 319/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 320/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 321/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 322/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 323/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 324/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 325/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 326/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 327/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 328/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 329/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 330/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 331/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 332/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 333/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 334/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 335/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 336/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 337/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 338/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 339/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 340/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 341/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 342/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 343/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 344/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 345/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 346/500\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 347/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 348/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 349/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 350/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 351/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 352/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 353/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 354/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 355/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 356/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 357/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 358/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 359/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 360/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 361/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 362/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 363/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 364/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 365/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 366/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 367/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 368/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 369/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 370/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 371/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 372/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 373/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 374/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 375/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 376/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 377/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 378/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 379/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 380/500\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 381/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 382/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 383/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 384/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 385/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 386/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 387/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 388/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 389/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 390/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 391/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 392/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 393/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 394/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 395/500\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 396/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 397/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 398/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 399/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 400/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 401/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 402/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 403/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 404/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 405/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 406/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 407/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 408/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 409/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 410/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 411/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 412/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 413/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 414/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 415/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 416/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 417/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 418/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 419/500\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 420/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 421/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 422/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 423/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 424/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 425/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 426/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 427/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 428/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 429/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 430/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 431/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 432/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 433/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 434/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 435/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 436/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 437/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 438/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 439/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 440/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 441/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 442/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 443/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 444/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 445/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 446/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 447/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 448/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 449/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 450/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 451/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 452/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 453/500\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 454/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 455/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 456/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 457/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 458/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 459/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 460/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 461/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 462/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 463/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 464/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 465/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 466/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 467/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 468/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 469/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 470/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 471/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 472/500\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 473/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 474/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 475/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 476/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 477/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 478/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 479/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 480/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 481/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 482/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 483/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 484/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 485/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 486/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 487/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 488/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 489/500\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 490/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 491/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 492/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 493/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 494/500\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 495/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 496/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 497/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 498/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 499/500\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 500/500\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.0038\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,epochs=500,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8073229607933438"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score,mean_absolute_error, mean_squared_error\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.04744728887875875\n",
      "Mean Squared Error (MSE): 0.003994833854181754\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Mean Squared Error (MSE): {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f41405ef810>]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
